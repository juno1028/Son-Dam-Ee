Sample 폴더에 담기는 건 뭘까?



1. Preprocess
python3 font2img.py --src_font=./fonts/source/NanumGothic.ttf --dst_font=./fonts/target/ --charset=./2350-common-hangul.txt  --sample_count=1000 --sample_dir=dir --filter=1 --shuffle=1

python3 package.py --dir=dir --save_dir=binary_save_directory --split_ratio=0.1

2. Experiment Layout

experiment/
└── data
    ├── train.obj
    └── val.obj

: 이런 파일 구조가 생성되어 있어야한다.


3. Train

python3 train.py --experiment_dir=./binary_save_directory --experiment_id=0 --batch_size=12 --lr=0.001 --epoch=100 --sample_steps=10 --schedule=10 --L1_penalty=100 --Lconst_penalty=15



* fine_tune

python3 train.py --experiment_dir=./binary_save_directory --experiment_id=0 --batch_size=14 --lr=0.001 --epoch=500 --sample_steps=10 --schedule=10 --L1_penalty=500 --Lconst_penalty=1000 --fine_tune=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27


* Transfer Learning

python3 package.py --dir=hand_writing_img_dir --save_dir=binary_save_directory --split_ratio=0.1

python3 train.py --experiment_dir=./binary_save_directory/ --experiment_id=0 --batch_size=12 --lr=0.001 --epoch=500 --sample_steps=10 --schedule=10 --L1_penalty=500 --Lconst_penalty=1000 --freeze_encoder=1 --fine_tune=28 --d_norm_type=sn --resume
(사람 폰트마다 다르게 적용해야 됨)

* Source 생성
python3 font2img.py --src_font=./fonts/source/NanumGothic.ttf --dst_font=./fonts/source/ --charset=./2350-common-hangul.txt  --sample_count=1000 --sample_dir=source_dir --filter=1 --shuffle=1

python3 package.py --dir=source_dir --save_dir=source_save_directory --split_ratio=0.1


워크스테이션 42번 : batch_size = 10
V100 : batch_size = 28

4. Infer and Interpolate - model 생성된 다음에 돌려볼 예정

python infer.py --model_dir=./binary_save_directory/ckpt/0_batch_12 --batch_size=12 --source_obj=./source_save_directory/val.obj --embedding_ids=3 --save_dir=inferred_dir/


(Interpolation)
python3 infer.py --model_dir=./binary_save_directory/ckpt/0_batch_14 --batch_size=14 --source_obj=./binary_save_directory/val.obj --embedding_ids=1,3 --save_dir=save_dir/frames/ --output_gif=./gif_path --interpolate=1 --steps=3 --uroboros=1

5. Extract

python3 extract.py --model_dir=./binary_save_directory/ckpt/0_batch_14 --batch_size=14 --source_obj=./binary_save_directory/val.obj --embedding_ids=28 --save_dir=extracted_dir/


python infer.py --model_dir= checkpoint_dir/ 
                --batch_size=10
                --source_obj=obj_path 
                --embedding_ids=label[s] of the font, separate by comma
                --save_dir=frames/ 
                --output_gif=gif_path 
                --interpolate=1 
                --steps=10
                --uroboros=1


927 1894 9094
ateam

예은 41,준범 57, 연주 27, 준오 42, 혜원 48



1. Training 모델

1 : SN-GAN : 57번에서 완료
python3 train.py --experiment_dir=./binary_save_directory --experiment_id=0 --batch_size=14 --lr=0.001 --epoch=100 --sample_steps=10 --schedule=10 --L1_penalty=100 --Lconst_penalty=15 --d_norm_type=sn

2 : cycle GAN(Loss) 사용(전처리도 같이 함) : 163번에서 가동중
python3 train.py --experiment_dir=./binary_save_directory --experiment_id=0 --batch_size=14 --lr=0.001 --epoch=100 --sample_steps=10 --schedule=10 --L1_penalty=100 --Lconst_penalty=15 --cycle_gan=True

3 : L1_penalty 상향 적용(2배)(전처리도 같이 함) : 42번에서 가동중
python3 train.py --experiment_dir=./binary_save_directory --experiment_id=0 --batch_size=12 --lr=0.001 --epoch=100 --sample_steps=10 --schedule=10 --L1_penalty=200 --Lconst_penalty=15

4 : Lconst_penalty 상향 적용(2배) : 48번에서 완료
python3 train.py --experiment_dir=./binary_save_directory --experiment_id=0 --batch_size=12 --lr=0.001 --epoch=100 --sample_steps=10 --schedule=10 --L1_penalty=100 --Lconst_penalty=30

5 : Perceptual Loss
https://gist.github.com/alper111/8233cdb0414b4cb5853f2f730ab95a49#file-vgg_perceptual_loss-py-L18


6 : 전처리 crop and centering : 41번에서 완료
Font2img_2.py로 crop
python3 train.py --experiment_dir=./binary_save_directory --experiment_id=0 --batch_size=14 --lr=0.001 --epoch=100 --sample_steps=10 --schedule=10 --L1_penalty=100 --Lconst_penalty=15


7 : Ltv_penalty(true_fake_loss) 상향 적용(2배) - 안 함

8 : category_loss(category_loss) 상향 적용(2배) - 안 함





* 현재 우리가 가지고 있는 모델 : 

1. 기본 모델 : 2가지(#163__완료, #42__완료 - 다운로드 완료)
2. 전처리(crop, centering, padding)만 된 거 : 1가지(#41__완료 - 다운로드 완료)
3. 전처리하고, L1_penalty 100에서 200으로 조정한 거 : 1가지(#42)
4. Lconst_penalty 15에서 30으로 조정한 거 : 1가지(#48__완료 - 다운로드 완료)
5. SNGAN(spectral normalization) 적용된 거 : 1가지(#57__완료 - 다운로드 완료)
6. 전처리하고, Cycle GAN 적용된 거 : 1가지(#163)
7. SRGAN : 적용 예정

8.
9.
10.

지금 놀고 있는 컴퓨터 : #41, #48, #57, #27



김준오 폴더

1253.png
2314.png


아스키코드.png


2350 -> 2441 어쩌구
210 -> 240

Ttf 파일 최소 2350




############################1228#############################

전이학습
-> image file 내보내기


Image file 모델에 넣고 파일명 형식 맞춰서 출력되게 하기


Shuffle 되서 나오는 문제 해결하기
SNGAN example 확인해보기(57번 컴퓨터 sample 폴더에서)

41번에서 extracting 해보고 있음
163에서 training 돌리는 중

손글씨 category embedding 어떻게 하지?

손글씨 이미지 파일을 넣은 다음에
모델이 학습되면
extract.py에서 추출하면 되려나


35번 들어가서 

근데 손글씨에서 잘 나와야 되는데


240개가 다 있는 거



- fine_tuning(transfer_learning 순서)
1. 왼쪽은 손글씨, 오른쪽은 고딕체인 사진 폴더를 프로젝트 폴더에 넣는다.(ex. 31_0123.png)
2. 210개의 사진들의 train.obj, val.obj를 생성한다.(package.py 활용)
3. train.obj랑 val.obj를 binary_save_directory/data에 넣는다.(덮어쓰기)
4. python3 train.py --experiment_dir=./binary_save_directory/ --experiment_id=0 --batch_size=14 --lr=0.001 --epoch=500 --sample_steps=10 --schedule=10 --L1_penalty=500 --Lconst_penalty=1000 --freeze_encoder=1 --fine_tune=28 --d_norm_type=sn —resume
5. 결과를 본다.


보라색 메모장이 됐어요~짜짠~~~^**^




